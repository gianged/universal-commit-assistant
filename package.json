{
  "name": "universal-commit-assistant",
  "displayName": "Universal Commit Assistant",
  "version": "1.4.0",
  "description": "Universal AI-powered commit message generator supporting multiple providers and languages (OpenAI, Anthropic, Gemini, Mistral, DeepSeek, Qwen, Ollama, LM Studio, OpenRouter)",
  "categories": [
    "Other",
    "Machine Learning",
    "SCM Providers"
  ],
  "keywords": [
    "git",
    "commit",
    "ai",
    "openai",
    "anthropic",
    "gemini",
    "mistral",
    "deepseek",
    "qwen",
    "ollama",
    "automation",
    "assistant",
    "universal",
    "multilingual",
    "conventional-commits",
    "source-control",
    "lm-studio",
    "openrouter",
    "commit-message",
    "productivity",
    "devtools",
    "vscode-extension"
  ],
  "homepage": "https://github.com/gianged/universal-commit-assistant",
  "bugs": {
    "url": "https://github.com/gianged/universal-commit-assistant/issues"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/gianged/universal-commit-assistant.git"
  },
  "license": "MIT",
  "publisher": "gianged",
  "main": "./out/extension.js",
  "scripts": {
    "compile": "tsc -p ./",
    "compile-web": "webpack",
    "package": "webpack --mode production --devtool hidden-source-map",
    "package-web": "webpack --mode production --devtool hidden-source-map",
    "release:dry-run": "semantic-release --dry-run",
    "semantic-release": "semantic-release",
    "vscode:prepublish": "npm run package",
    "watch": "tsc -watch -p ./",
    "watch-web": "webpack --watch"
  },
  "contributes": {
    "commands": [
      {
        "command": "universal-commit-assistant.generateCommitMessage",
        "title": "Generate Universal Commit Message",
        "icon": "$(sparkle)"
      },
      {
        "command": "universal-commit-assistant.clearAllSecrets",
        "title": "Universal Commit Assistant: Clear All API Keys",
        "icon": "$(trash)"
      },
      {
        "command": "universal-commit-assistant.openSettings",
        "title": "Universal Commit Assistant: Open Settings"
      },
      {
        "command": "universal-commit-assistant.showSecretStatus",
        "title": "Universal Commit Assistant: Show API Key Status"
      }
    ],
    "configuration": [
      {
        "title": "General",
        "properties": {
          "universal-commit-assistant.provider": {
            "type": "string",
            "default": "openai",
            "enum": [
              "openai",
              "anthropic",
              "gemini",
              "mistral",
              "deepseek",
              "qwen",
              "openrouter",
              "ollama",
              "lmstudio"
            ],
            "enumDescriptions": [
              "OpenAI GPT models",
              "Anthropic Claude models",
              "Google Gemini models",
              "Mistral AI models",
              "DeepSeek models",
              "Alibaba Qwen models",
              "OpenRouter proxy service",
              "Local Ollama instance",
              "Local LM Studio instance"
            ],
            "description": "AI provider to use for generating commit messages",
            "order": 1
          },
          "universal-commit-assistant.messageStyle": {
            "type": "string",
            "default": "conventional",
            "enum": [
              "conventional",
              "concise",
              "detailed",
              "custom"
            ],
            "enumDescriptions": [
              "Conventional Commits format with type prefix (feat:, fix:, docs:, etc.)",
              "Very short messages without type prefix (max 50 characters)",
              "Detailed multi-line messages with explanations and bullet points",
              "Use custom prompt template"
            ],
            "description": "Style of commit messages to generate",
            "order": 2
          },
          "universal-commit-assistant.language": {
            "type": "string",
            "default": "english",
            "enum": [
              "english",
              "chinese",
              "spanish",
              "french",
              "russian",
              "japanese",
              "korean",
              "vietnamese"
            ],
            "enumDescriptions": [
              "English",
              "中文 (Chinese)",
              "Español (Spanish)",
              "Français (French)",
              "Русский (Russian)",
              "日本語 (Japanese)",
              "한국어 (Korean)",
              "Tiếng Việt (Vietnamese)"
            ],
            "description": "Language for generated commit messages",
            "order": 3
          },
          "universal-commit-assistant.customPrompt": {
            "type": "string",
            "default": "",
            "description": "Custom prompt template for commit message generation (used when messageStyle is 'custom')",
            "order": 4
          },
          "universal-commit-assistant.systemPrompt": {
            "type": "string",
            "default": "You are a git commit message generator. Return ONLY the commit message with no additional text, explanations, or prefixes.",
            "description": "Custom system prompt for AI providers",
            "order": 5
          },
          "universal-commit-assistant.temperature": {
            "type": "number",
            "default": 0.3,
            "minimum": 0,
            "maximum": 2,
            "description": "Temperature for AI responses (0 = deterministic, 2 = very creative)",
            "order": 6
          },
          "universal-commit-assistant.maxTokens": {
            "type": "number",
            "default": 200,
            "minimum": 100,
            "maximum": 500,
            "description": "Maximum tokens for generated commit messages",
            "order": 7
          },
          "universal-commit-assistant.maxDiffLength": {
            "type": "number",
            "default": 3000,
            "minimum": 1000,
            "maximum": 10000,
            "description": "Maximum characters of git diff to send to AI (uses smart truncation for larger diffs)",
            "order": 8
          },
          "universal-commit-assistant.detectFirstCommit": {
            "type": "boolean",
            "default": true,
            "description": "Automatically detect and generate appropriate initial commit messages for first commits",
            "order": 9
          },
          "universal-commit-assistant.enableAnalytics": {
            "type": "boolean",
            "default": false,
            "description": "Enable usage analytics (no sensitive data is collected)",
            "order": 10
          }
        }
      },
      {
        "title": "Cloud Providers",
        "properties": {
          "universal-commit-assistant.openai.model": {
            "type": "string",
            "default": "gpt-5.1",
            "enum": [
              "gpt-5.1",
              "gpt-5.1-codex",
              "gpt-5.1-codex-mini",
              "gpt-5-mini",
              "gpt-5"
            ],
            "enumDescriptions": [
              "GPT-5.1 - Latest model balancing intelligence and speed (recommended)",
              "GPT-5.1 Codex - Optimized for coding tasks",
              "GPT-5.1 Codex Mini - Fast coding model",
              "GPT-5 Mini - Fast and cost-effective",
              "GPT-5 - Full capability flagship model"
            ],
            "description": "OpenAI model to use"
          },
          "universal-commit-assistant.anthropic.model": {
            "type": "string",
            "default": "claude-haiku-4-5-20251001",
            "enum": [
              "claude-haiku-4-5-20251001",
              "claude-sonnet-4-5-20250929",
              "claude-opus-4-1-20250805"
            ],
            "enumDescriptions": [
              "Claude Haiku 4.5 - Fast and cost-effective (recommended)",
              "Claude Sonnet 4.5 - Enhanced reasoning and coding capabilities",
              "Claude Opus 4.1 - Most capable model with extended thinking"
            ],
            "description": "Anthropic model to use"
          },
          "universal-commit-assistant.gemini.model": {
            "type": "string",
            "default": "gemini-3-pro",
            "enum": [
              "gemini-3-pro",
              "gemini-3-pro-preview-11-2025",
              "gemini-2.5-flash",
              "gemini-2.5-pro"
            ],
            "enumDescriptions": [
              "Gemini 3 Pro - Latest flagship model with 1M context (recommended)",
              "Gemini 3 Pro Preview - Preview version of Gemini 3",
              "Gemini 2.5 Flash - Fast and cost-effective",
              "Gemini 2.5 Pro - Advanced reasoning with thinking mode"
            ],
            "description": "Gemini model to use"
          },
          "universal-commit-assistant.mistral.model": {
            "type": "string",
            "default": "mistral-small-latest",
            "description": "Mistral model to use"
          },
          "universal-commit-assistant.openrouter.model": {
            "type": "string",
            "default": "openai/gpt-5-mini",
            "description": "OpenRouter model to use"
          },
          "universal-commit-assistant.deepseek.model": {
            "type": "string",
            "default": "deepseek-chat",
            "enum": [
              "deepseek-chat",
              "deepseek-reasoner"
            ],
            "enumDescriptions": [
              "DeepSeek-V3.1 (Non-thinking Mode) - Fast general purpose model",
              "DeepSeek-V3.1 (Thinking Mode) - Reasoning model for complex tasks"
            ],
            "description": "DeepSeek model to use"
          },
          "universal-commit-assistant.qwen.model": {
            "type": "string",
            "default": "qwen-plus",
            "enum": [
              "qwen-plus",
              "qwen-max",
              "qwen-turbo"
            ],
            "enumDescriptions": [
              "Qwen Plus - Balanced performance and cost (recommended)",
              "Qwen Max - Most capable model",
              "Qwen Turbo - Fastest model with 1M context"
            ],
            "description": "Qwen model to use"
          },
          "universal-commit-assistant.qwen.baseUrl": {
            "type": "string",
            "default": "https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
            "enum": [
              "https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
              "https://dashscope.aliyuncs.com/compatible-mode/v1"
            ],
            "enumDescriptions": [
              "International (Singapore) - For users outside China",
              "China (Beijing) - For users in mainland China"
            ],
            "description": "Qwen DashScope API region"
          }
        }
      },
      {
        "title": "Local Providers",
        "properties": {
          "universal-commit-assistant.ollama.model": {
            "type": "string",
            "default": "llama3.2",
            "description": "Ollama model to use"
          },
          "universal-commit-assistant.ollama.baseUrl": {
            "type": "string",
            "default": "http://localhost:11434",
            "description": "Ollama server base URL"
          },
          "universal-commit-assistant.lmstudio.model": {
            "type": "string",
            "default": "llama-3.1-8b-instruct",
            "description": "LM Studio model to use"
          },
          "universal-commit-assistant.lmstudio.baseUrl": {
            "type": "string",
            "default": "http://localhost:1234",
            "description": "LM Studio server base URL"
          }
        }
      }
    ],
    "menus": {
      "scm/title": [
        {
          "command": "universal-commit-assistant.generateCommitMessage",
          "when": "scmProvider == git",
          "group": "navigation"
        }
      ]
    }
  },
  "activationEvents": [
    "onStartupFinished"
  ],
  "dependencies": {
    "axios": "^1.12.2"
  },
  "devDependencies": {
    "@semantic-release/changelog": "^6.0.3",
    "@semantic-release/exec": "^7.1.0",
    "@semantic-release/git": "^10.0.1",
    "@semantic-release/github": "^12.0.0",
    "@semantic-release/npm": "^13.0.0",
    "@types/node": "24.8.1",
    "@types/vscode": "^1.95.0",
    "@vscode/vsce": "^3.6.2",
    "semantic-release": "^25.0.0",
    "ts-loader": "^9.5.4",
    "typescript": "^5.9.3",
    "webpack": "^5.102.1",
    "webpack-cli": "^6.0.1"
  },
  "engines": {
    "vscode": "^1.95.0"
  },
  "icon": "logo.png"
}
